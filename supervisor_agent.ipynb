{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Annotated\n",
    "from typing import Literal\n",
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "from langchain_core.tools import tool\n",
    "from langchain_experimental.utilities import PythonREPL\n",
    "from typing_extensions import TypedDict\n",
    "from langgraph.graph import MessagesState, END,StateGraph, START\n",
    "from langgraph.types import Command\n",
    "from langchain_core.messages import HumanMessage\n",
    "from langgraph.prebuilt import create_react_agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "groq_model=ChatGroq(model=\"deepseek-r1-distill-llama-70b\",api_key=\"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\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<think>\\n\\n</think>\\n\\nHello! How can I assist you today? ðŸ˜Š'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "groq_model.invoke(\"hi\").content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    import re\n",
    "    clean_text = re.sub(r\"<think>.*?</think>\\s*\", \"\", text, flags=re.DOTALL)\n",
    "    return clean_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "response=groq_model.invoke(\"hi\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<think>\\n\\n</think>\\n\\nHello! How can I assist you today? ðŸ˜Š'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hello! How can I assist you today? ðŸ˜Š'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_text(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "tavaily_tool=TavilySearchResults()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'url': 'https://en.wikipedia.org/wiki/Gross_domestic_product',\n",
       "  'content': 'Gross domestic product (GDP) is a monetary measure of the total market value[1] of all the final goods and services produced and rendered in a specific time period by a country[2] or countries.[3][4][5] GDP is often used to measure the economic performance of a country or region.[2] Several national and international economic organizations maintain definitions of GDP, such as the OECD and the International Monetary Fund.[6][7] [...] Appearance\\nmove to sidebar hide\\nFrom Wikipedia, the free encyclopedia\\nMarket value of goods and services produced within a country\\n\"GDP\" redirects here. For other uses, see GDP (disambiguation). [...] U.S. GDP computed on the expenditure basis\\nGDP (Y) is the sum of consumption (C), investment (I), government expenditures (G) and net exports (X âˆ’ M).\\nY = C + I + G + (X âˆ’ M)\\nHere is a description of each GDP component:'},\n",
       " {'url': 'https://www.investopedia.com/terms/g/gdp.asp',\n",
       "  'content': 'What Is Gross Domestic Product (GDP)?\\nGross domestic product (GDP) is the total monetary or market value of all the finished goods and services produced within a countryâ€™s borders in a specific time period. As a broad measure of overall domestic production, it functions as a comprehensive scorecard of a given countryâ€™s economic health. [...] Gross domestic product is the monetary value of all finished goods and services made within a country during a specific period.\\nGDP provides an economic snapshot of a country, used to estimate the size of an economy and its growth rate.\\nGDP can be calculated in three ways, using expenditures, production, or incomes, and it can be adjusted for inflation and population to provide deeper insights.\\nReal GDP takes into account the effects of inflation, while nominal GDP does not. [...] Gross domestic product is a measurement that seeks to capture a countryâ€™s economic output. Countries with larger GDPs will have a greater amount of goods and services generated within them, and will generally have a higher standard of living. For this reason, many citizens and political leaders see GDP growth as an important measure of national success, often referring to GDP growth and economic growth interchangeably. Due to various limitations, however, many economists have argued that GDP'},\n",
       " {'url': 'https://www.oecd.org/en/data/indicators/nominal-gross-domestic-product-gdp.html',\n",
       "  'content': 'Nominal gross domestic product (GDP)\\nGross domestic product (GDP) is the standard measure of the value added created through the production of goods and services in a country during a certain period.\\nIndicator\\nAvailable in: English\\n\\nEnglish\\nfranÃ§ais [...] Select a language\\nClose\\nEnglish\\nfranÃ§ais\\nApply\\nCancel\\nShare\\nFacebook Twitter LinkedIn\\nDefinition\\nGross domestic product (GDP) is the standard measure of the value added created through the production of goods and services in a country during a certain period. [...] Dataset\\nGDP and Non-financial Accounts\\nGross Domestic Product (GDP) measures countriesâ€™ economic growth and is the most well-known indicator from the national accounts. The non-financial accounts provide detailed information for each economy, including measures of production, income, consumption, saving and borrowing.\\n\\n\\nDataset\\nComposite Leading Indicators (CLI)\\nThe OECD Composite Leading Indicators (CLIs) are designed to anticipate turning points and economic fluctuations relative to trend.'},\n",
       " {'url': 'https://www.bankofengland.co.uk/explainers/what-is-gdp',\n",
       "  'content': \"Gross domestic product (GDP) is a measure of the size and health of a country's economy over a period (usually one quarter or one year).\"},\n",
       " {'url': 'https://www.commerce.gov/tags/gross-domestic-product-gdp',\n",
       "  'content': 'Produced by the Bureau of Economic Analysis, Gross Domestic Product (GDP) data is ranked as one of the three most influential economic measures that affect U.S. financial markets. GDP is the value of the goods and services produced by the nationâ€™s economy less the value of the goods and services used up in production. GDP is also equal to the sum of personal consumption expenditures, gross private domestic investment, net exports of goods and services, and government consumption expenditures'}]"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tavaily_tool.invoke(\"what is a gdp?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "code = \"\"\"\n",
    "x = 5\n",
    "y = x * 2\n",
    "print(y)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "repl=PythonREPL()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'10\\n'"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "repl.run(code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def python_repl_tool(\n",
    "    code: Annotated[str, \"The python code to execute to generate your chart.\"],\n",
    "):\n",
    "    \"\"\"Use this to execute python code and do math. If you want to see the output of a value,\n",
    "    you should print it out with `print(...)`. This is visible to the user.\"\"\"\n",
    "    \n",
    "    try:\n",
    "        result = repl.run(code)\n",
    "    except BaseException as e:\n",
    "        return f\"Failed to execute. Error: {repr(e)}\"\n",
    "    \n",
    "    result_str = f\"Successfully executed:\\n\\`\\`\\`python\\n{code}\\n\\`\\`\\`\\nStdout: {result}\"\n",
    "    return result_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully executed:\n",
      "\\`\\`\\`python\n",
      "\n",
      "x = 5\n",
      "y = x * 2\n",
      "print(y)\n",
      "\n",
      "\\`\\`\\`\n",
      "Stdout: 10\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(python_repl_tool.invoke(code))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "members=[\"researcher\",\"coder\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "options=members+[\"FINISH\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['researcher', 'coder', 'FINISH']"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Router(TypedDict):\n",
    "    \"\"\"Worker to route to next. If no workers needed, route to FINISH.\"\"\"\n",
    "    next: Literal['researcher', 'coder', 'FINISH']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "class State(MessagesState):\n",
    "    next:str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt=f\"\"\"\n",
    "You are a supervisor, tasked with managing a conversation between the following workers: {members}. \n",
    "Given the following user request, respond with the worker to act next. \n",
    "Each worker will perform a task and respond with their results and status. \n",
    "When finished, respond with FINISH.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'role': 'system',\n",
       "  'content': \"\\nYou are a supervisor, tasked with managing a conversation between the following workers: ['researcher', 'coder']. \\nGiven the following user request, respond with the worker to act next. \\nEach worker will perform a task and respond with their results and status. \\nWhen finished, respond with FINISH.\\n\"}]"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[{\"role\": \"system\", \"content\": system_prompt},]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "state={\"next\":[\"hi\"]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['hi']"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state[\"next\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'role': 'system',\n",
       "  'content': \"\\nYou are a supervisor, tasked with managing a conversation between the following workers: ['researcher', 'coder']. \\nGiven the following user request, respond with the worker to act next. \\nEach worker will perform a task and respond with their results and status. \\nWhen finished, respond with FINISH.\\n\"},\n",
       " 'hi']"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[{\"role\": \"system\", \"content\": system_prompt},] + state[\"next\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "def supervisor_node(state: State) -> Command[Literal[\"researcher\", \"coder\", \"__end__\"]]:\n",
    "    \n",
    "    messages = [{\"role\": \"system\", \"content\": system_prompt},] + state[\"messages\"]\n",
    "    \n",
    "    response = groq_model.with_structured_output(Router).invoke(messages)\n",
    "    \n",
    "    goto = response[\"next\"]\n",
    "    \n",
    "    print(\"below my goto**********************************\")\n",
    "    \n",
    "    print(goto)\n",
    "    \n",
    "    if goto == \"FINISH\":\n",
    "        goto = END\n",
    "        \n",
    "    return Command(goto=goto, update={\"next\": goto})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "def research_node(state: State) -> Command[Literal[\"supervisor\"]]:\n",
    "    \n",
    "    research_agent = create_react_agent(groq_model, tools=[tavaily_tool], prompt=\"You are a researcher. DO NOT do any math.\")\n",
    "    \n",
    "    result = research_agent.invoke(state)\n",
    "    \n",
    "    return Command(\n",
    "        update={\n",
    "            \"messages\": [\n",
    "                HumanMessage(content=result[\"messages\"][-1].content, name=\"researcher\")\n",
    "            ]\n",
    "        },\n",
    "        goto=\"supervisor\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "def code_node(state: State) -> Command[Literal[\"supervisor\"]]:\n",
    "    \n",
    "    code_agent = create_react_agent(groq_model, tools=[python_repl_tool])\n",
    "    \n",
    "    result = code_agent.invoke(state)\n",
    "    \n",
    "    return Command(\n",
    "        update={\n",
    "            \"messages\": [\n",
    "                HumanMessage(content=result[\"messages\"][-1].content, name=\"coder\")\n",
    "            ]\n",
    "        },\n",
    "        goto=\"supervisor\",\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph=StateGraph(State)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x17e878a9930>"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph.add_node(\"supervisor\",supervisor_node)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x17e878a9930>"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph.add_node(\"researcher\", research_node)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x17e878a9930>"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph.add_node(\"coder\", code_node)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x17e878a9930>"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph.add_edge(START,\"supervisor\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "app=graph.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display, Image\n",
    "\n",
    "display(Image(app.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "below my goto**********************************\n",
      "researcher\n",
      "((), {'supervisor': {'next': 'researcher'}})\n",
      "----\n",
      "(('researcher:b52c420c-2101-54a7-c81c-971a5d1f4384',), {'agent': {'messages': [AIMessage(content='The square root of 42 is approximately 6.4807.', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 441, 'prompt_tokens': 178, 'total_tokens': 619, 'completion_time': 1.603636364, 'prompt_time': 0.013837981, 'queue_time': 0.15892967, 'total_time': 1.617474345}, 'model_name': 'deepseek-r1-distill-llama-70b', 'system_fingerprint': 'fp_2834edf0f4', 'finish_reason': 'stop', 'logprobs': None}, id='run-b0acd46c-80dc-4015-aa73-1f44b77b2b90-0', usage_metadata={'input_tokens': 178, 'output_tokens': 441, 'total_tokens': 619})]}})\n",
      "----\n",
      "((), {'researcher': {'messages': [HumanMessage(content='The square root of 42 is approximately 6.4807.', additional_kwargs={}, response_metadata={}, name='researcher')]}})\n",
      "----\n",
      "below my goto**********************************\n",
      "researcher\n",
      "((), {'supervisor': {'next': 'researcher'}})\n",
      "----\n",
      "(('researcher:a6e4fb23-87bb-5d95-c1e1-f46cd2abc7cf',), {'agent': {'messages': [AIMessage(content='The square root of 42 is approximately 6.4807.', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 755, 'prompt_tokens': 193, 'total_tokens': 948, 'completion_time': 2.745454545, 'prompt_time': 0.016932456, 'queue_time': 0.047712455, 'total_time': 2.762387001}, 'model_name': 'deepseek-r1-distill-llama-70b', 'system_fingerprint': 'fp_2834edf0f4', 'finish_reason': 'stop', 'logprobs': None}, id='run-84d3088d-ae9e-465d-bd5a-24fb4bf62fff-0', usage_metadata={'input_tokens': 193, 'output_tokens': 755, 'total_tokens': 948})]}})\n",
      "----\n",
      "((), {'researcher': {'messages': [HumanMessage(content='The square root of 42 is approximately 6.4807.', additional_kwargs={}, response_metadata={}, name='researcher')]}})\n",
      "----\n",
      "below my goto**********************************\n",
      "researcher\n",
      "((), {'supervisor': {'next': 'researcher'}})\n",
      "----\n",
      "(('researcher:858ac381-01ee-afe9-2314-a1c50e992043',), {'agent': {'messages': [AIMessage(content='\\n\\nThe square root of 42 is approximately 6.4807.', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 16, 'prompt_tokens': 208, 'total_tokens': 224, 'completion_time': 0.058181818, 'prompt_time': 0.015754949, 'queue_time': 0.280799362, 'total_time': 0.073936767}, 'model_name': 'deepseek-r1-distill-llama-70b', 'system_fingerprint': 'fp_2834edf0f4', 'finish_reason': 'stop', 'logprobs': None}, id='run-273a3bad-196c-4036-8603-d9563873a0c6-0', usage_metadata={'input_tokens': 208, 'output_tokens': 16, 'total_tokens': 224})]}})\n",
      "----\n",
      "((), {'researcher': {'messages': [HumanMessage(content='\\n\\nThe square root of 42 is approximately 6.4807.', additional_kwargs={}, response_metadata={}, name='researcher')]}})\n",
      "----\n",
      "below my goto**********************************\n",
      "researcher\n",
      "((), {'supervisor': {'next': 'researcher'}})\n",
      "----\n",
      "(('researcher:2e1564aa-6c60-7272-974c-f1a5de0e9d3f',), {'agent': {'messages': [AIMessage(content='\\n\\nThe square root of 42 is approximately 6.4807.', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 16, 'prompt_tokens': 224, 'total_tokens': 240, 'completion_time': 0.058181818, 'prompt_time': 0.013637907, 'queue_time': 2.5454649799999998, 'total_time': 0.071819725}, 'model_name': 'deepseek-r1-distill-llama-70b', 'system_fingerprint': 'fp_fc872c073e', 'finish_reason': 'stop', 'logprobs': None}, id='run-77863d7c-391b-4a09-9095-fb5020cc0e3c-0', usage_metadata={'input_tokens': 224, 'output_tokens': 16, 'total_tokens': 240})]}})\n",
      "----\n",
      "((), {'researcher': {'messages': [HumanMessage(content='\\n\\nThe square root of 42 is approximately 6.4807.', additional_kwargs={}, response_metadata={}, name='researcher')]}})\n",
      "----\n"
     ]
    },
    {
     "ename": "BadRequestError",
     "evalue": "Error code: 400 - {'error': {'message': \"Failed to call a function. Please adjust your prompt. See 'failed_generation' for more details.\", 'type': 'invalid_request_error', 'code': 'tool_use_failed', 'failed_generation': ''}}",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mBadRequestError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[106], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# With the graph created, we can now invoke it and see how it performs!\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m s \u001b[38;5;129;01min\u001b[39;00m app\u001b[38;5;241m.\u001b[39mstream({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m: [(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muser\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWhat\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124ms the square root of 42?\u001b[39m\u001b[38;5;124m\"\u001b[39m)]}, subgraphs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[0;32m      3\u001b[0m     \u001b[38;5;28mprint\u001b[39m(s)\n\u001b[0;32m      4\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m----\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\sunny\\langgraph-end-to-end\\venv\\lib\\site-packages\\langgraph\\pregel\\__init__.py:1724\u001b[0m, in \u001b[0;36mPregel.stream\u001b[1;34m(self, input, config, stream_mode, output_keys, interrupt_before, interrupt_after, debug, subgraphs)\u001b[0m\n\u001b[0;32m   1718\u001b[0m     \u001b[38;5;66;03m# Similarly to Bulk Synchronous Parallel / Pregel model\u001b[39;00m\n\u001b[0;32m   1719\u001b[0m     \u001b[38;5;66;03m# computation proceeds in steps, while there are channel updates.\u001b[39;00m\n\u001b[0;32m   1720\u001b[0m     \u001b[38;5;66;03m# Channel updates from step N are only visible in step N+1\u001b[39;00m\n\u001b[0;32m   1721\u001b[0m     \u001b[38;5;66;03m# channels are guaranteed to be immutable for the duration of the step,\u001b[39;00m\n\u001b[0;32m   1722\u001b[0m     \u001b[38;5;66;03m# with channel updates applied only at the transition between steps.\u001b[39;00m\n\u001b[0;32m   1723\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m loop\u001b[38;5;241m.\u001b[39mtick(input_keys\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_channels):\n\u001b[1;32m-> 1724\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m runner\u001b[38;5;241m.\u001b[39mtick(\n\u001b[0;32m   1725\u001b[0m             loop\u001b[38;5;241m.\u001b[39mtasks\u001b[38;5;241m.\u001b[39mvalues(),\n\u001b[0;32m   1726\u001b[0m             timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstep_timeout,\n\u001b[0;32m   1727\u001b[0m             retry_policy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mretry_policy,\n\u001b[0;32m   1728\u001b[0m             get_waiter\u001b[38;5;241m=\u001b[39mget_waiter,\n\u001b[0;32m   1729\u001b[0m         ):\n\u001b[0;32m   1730\u001b[0m             \u001b[38;5;66;03m# emit output\u001b[39;00m\n\u001b[0;32m   1731\u001b[0m             \u001b[38;5;28;01myield from\u001b[39;00m output()\n\u001b[0;32m   1732\u001b[0m \u001b[38;5;66;03m# emit output\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\sunny\\langgraph-end-to-end\\venv\\lib\\site-packages\\langgraph\\pregel\\runner.py:302\u001b[0m, in \u001b[0;36mPregelRunner.tick\u001b[1;34m(self, tasks, reraise, timeout, retry_policy, get_waiter)\u001b[0m\n\u001b[0;32m    300\u001b[0m \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[0;32m    301\u001b[0m \u001b[38;5;66;03m# panic on failure or timeout\u001b[39;00m\n\u001b[1;32m--> 302\u001b[0m \u001b[43m_panic_or_proceed\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    303\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfutures\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdone\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43munion\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mfutures\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitems\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    304\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpanic\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreraise\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    305\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\sunny\\langgraph-end-to-end\\venv\\lib\\site-packages\\langgraph\\pregel\\runner.py:619\u001b[0m, in \u001b[0;36m_panic_or_proceed\u001b[1;34m(futs, timeout_exc_cls, panic)\u001b[0m\n\u001b[0;32m    617\u001b[0m         \u001b[38;5;66;03m# raise the exception\u001b[39;00m\n\u001b[0;32m    618\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m panic:\n\u001b[1;32m--> 619\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m exc\n\u001b[0;32m    620\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m inflight:\n\u001b[0;32m    621\u001b[0m     \u001b[38;5;66;03m# if we got here means we timed out\u001b[39;00m\n\u001b[0;32m    622\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m inflight:\n\u001b[0;32m    623\u001b[0m         \u001b[38;5;66;03m# cancel all pending tasks\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\sunny\\langgraph-end-to-end\\venv\\lib\\site-packages\\langgraph\\pregel\\executor.py:83\u001b[0m, in \u001b[0;36mBackgroundExecutor.done\u001b[1;34m(self, task)\u001b[0m\n\u001b[0;32m     81\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Remove the task from the tasks dict when it's done.\"\"\"\u001b[39;00m\n\u001b[0;32m     82\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 83\u001b[0m     \u001b[43mtask\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     84\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m GraphBubbleUp:\n\u001b[0;32m     85\u001b[0m     \u001b[38;5;66;03m# This exception is an interruption signal, not an error\u001b[39;00m\n\u001b[0;32m     86\u001b[0m     \u001b[38;5;66;03m# so we don't want to re-raise it on exit\u001b[39;00m\n\u001b[0;32m     87\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtasks\u001b[38;5;241m.\u001b[39mpop(task)\n",
      "File \u001b[1;32mc:\\Users\\sunny\\langgraph-end-to-end\\venv\\lib\\concurrent\\futures\\_base.py:451\u001b[0m, in \u001b[0;36mFuture.result\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    449\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CancelledError()\n\u001b[0;32m    450\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;241m==\u001b[39m FINISHED:\n\u001b[1;32m--> 451\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__get_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    453\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_condition\u001b[38;5;241m.\u001b[39mwait(timeout)\n\u001b[0;32m    455\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;129;01min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n",
      "File \u001b[1;32mc:\\Users\\sunny\\langgraph-end-to-end\\venv\\lib\\concurrent\\futures\\_base.py:403\u001b[0m, in \u001b[0;36mFuture.__get_result\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    401\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception:\n\u001b[0;32m    402\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 403\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception\n\u001b[0;32m    404\u001b[0m     \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    405\u001b[0m         \u001b[38;5;66;03m# Break a reference cycle with the exception in self._exception\u001b[39;00m\n\u001b[0;32m    406\u001b[0m         \u001b[38;5;28mself\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\sunny\\langgraph-end-to-end\\venv\\lib\\concurrent\\futures\\thread.py:58\u001b[0m, in \u001b[0;36m_WorkItem.run\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     55\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m     57\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 58\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfn(\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkwargs)\n\u001b[0;32m     59\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[0;32m     60\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfuture\u001b[38;5;241m.\u001b[39mset_exception(exc)\n",
      "File \u001b[1;32mc:\\Users\\sunny\\langgraph-end-to-end\\venv\\lib\\site-packages\\langgraph\\pregel\\retry.py:40\u001b[0m, in \u001b[0;36mrun_with_retry\u001b[1;34m(task, retry_policy, configurable)\u001b[0m\n\u001b[0;32m     38\u001b[0m     task\u001b[38;5;241m.\u001b[39mwrites\u001b[38;5;241m.\u001b[39mclear()\n\u001b[0;32m     39\u001b[0m     \u001b[38;5;66;03m# run the task\u001b[39;00m\n\u001b[1;32m---> 40\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtask\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mproc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtask\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minput\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     41\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ParentCommand \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[0;32m     42\u001b[0m     ns: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m=\u001b[39m config[CONF][CONFIG_KEY_CHECKPOINT_NS]\n",
      "File \u001b[1;32mc:\\Users\\sunny\\langgraph-end-to-end\\venv\\lib\\site-packages\\langgraph\\utils\\runnable.py:506\u001b[0m, in \u001b[0;36mRunnableSeq.invoke\u001b[1;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[0;32m    502\u001b[0m config \u001b[38;5;241m=\u001b[39m patch_config(\n\u001b[0;32m    503\u001b[0m     config, callbacks\u001b[38;5;241m=\u001b[39mrun_manager\u001b[38;5;241m.\u001b[39mget_child(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mseq:step:\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;250m \u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    504\u001b[0m )\n\u001b[0;32m    505\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m--> 506\u001b[0m     \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m step\u001b[38;5;241m.\u001b[39minvoke(\u001b[38;5;28minput\u001b[39m, config, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    507\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    508\u001b[0m     \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m step\u001b[38;5;241m.\u001b[39minvoke(\u001b[38;5;28minput\u001b[39m, config)\n",
      "File \u001b[1;32mc:\\Users\\sunny\\langgraph-end-to-end\\venv\\lib\\site-packages\\langgraph\\utils\\runnable.py:270\u001b[0m, in \u001b[0;36mRunnableCallable.invoke\u001b[1;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[0;32m    268\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    269\u001b[0m     context\u001b[38;5;241m.\u001b[39mrun(_set_config_context, config)\n\u001b[1;32m--> 270\u001b[0m     ret \u001b[38;5;241m=\u001b[39m context\u001b[38;5;241m.\u001b[39mrun(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunc, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    271\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(ret, Runnable) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrecurse:\n\u001b[0;32m    272\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ret\u001b[38;5;241m.\u001b[39minvoke(\u001b[38;5;28minput\u001b[39m, config)\n",
      "Cell \u001b[1;32mIn[96], line 5\u001b[0m, in \u001b[0;36msupervisor_node\u001b[1;34m(state)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21msupervisor_node\u001b[39m(state: State) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Command[Literal[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresearcher\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcoder\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__end__\u001b[39m\u001b[38;5;124m\"\u001b[39m]]:\n\u001b[0;32m      3\u001b[0m     messages \u001b[38;5;241m=\u001b[39m [{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrole\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msystem\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m\"\u001b[39m: system_prompt},] \u001b[38;5;241m+\u001b[39m state[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m----> 5\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mgroq_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwith_structured_output\u001b[49m\u001b[43m(\u001b[49m\u001b[43mRouter\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      7\u001b[0m     goto \u001b[38;5;241m=\u001b[39m response[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnext\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m      9\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbelow my goto**********************************\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\sunny\\langgraph-end-to-end\\venv\\lib\\site-packages\\langchain_core\\runnables\\base.py:3027\u001b[0m, in \u001b[0;36mRunnableSequence.invoke\u001b[1;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[0;32m   3025\u001b[0m context\u001b[38;5;241m.\u001b[39mrun(_set_config_context, config)\n\u001b[0;32m   3026\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m-> 3027\u001b[0m     \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m context\u001b[38;5;241m.\u001b[39mrun(step\u001b[38;5;241m.\u001b[39minvoke, \u001b[38;5;28minput\u001b[39m, config, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   3028\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   3029\u001b[0m     \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m context\u001b[38;5;241m.\u001b[39mrun(step\u001b[38;5;241m.\u001b[39minvoke, \u001b[38;5;28minput\u001b[39m, config)\n",
      "File \u001b[1;32mc:\\Users\\sunny\\langgraph-end-to-end\\venv\\lib\\site-packages\\langchain_core\\runnables\\base.py:5365\u001b[0m, in \u001b[0;36mRunnableBindingBase.invoke\u001b[1;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[0;32m   5359\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21minvoke\u001b[39m(\n\u001b[0;32m   5360\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   5361\u001b[0m     \u001b[38;5;28minput\u001b[39m: Input,\n\u001b[0;32m   5362\u001b[0m     config: Optional[RunnableConfig] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   5363\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Optional[Any],\n\u001b[0;32m   5364\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Output:\n\u001b[1;32m-> 5365\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbound\u001b[38;5;241m.\u001b[39minvoke(\n\u001b[0;32m   5366\u001b[0m         \u001b[38;5;28minput\u001b[39m,\n\u001b[0;32m   5367\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_merge_configs(config),\n\u001b[0;32m   5368\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m{\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkwargs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs},\n\u001b[0;32m   5369\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\sunny\\langgraph-end-to-end\\venv\\lib\\site-packages\\langchain_core\\language_models\\chat_models.py:307\u001b[0m, in \u001b[0;36mBaseChatModel.invoke\u001b[1;34m(self, input, config, stop, **kwargs)\u001b[0m\n\u001b[0;32m    296\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21minvoke\u001b[39m(\n\u001b[0;32m    297\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    298\u001b[0m     \u001b[38;5;28minput\u001b[39m: LanguageModelInput,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    302\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[0;32m    303\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m BaseMessage:\n\u001b[0;32m    304\u001b[0m     config \u001b[38;5;241m=\u001b[39m ensure_config(config)\n\u001b[0;32m    305\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(\n\u001b[0;32m    306\u001b[0m         ChatGeneration,\n\u001b[1;32m--> 307\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgenerate_prompt(\n\u001b[0;32m    308\u001b[0m             [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_convert_input(\u001b[38;5;28minput\u001b[39m)],\n\u001b[0;32m    309\u001b[0m             stop\u001b[38;5;241m=\u001b[39mstop,\n\u001b[0;32m    310\u001b[0m             callbacks\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcallbacks\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m    311\u001b[0m             tags\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtags\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m    312\u001b[0m             metadata\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetadata\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m    313\u001b[0m             run_name\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_name\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m    314\u001b[0m             run_id\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_id\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m    315\u001b[0m             \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m    316\u001b[0m         )\u001b[38;5;241m.\u001b[39mgenerations[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m],\n\u001b[0;32m    317\u001b[0m     )\u001b[38;5;241m.\u001b[39mmessage\n",
      "File \u001b[1;32mc:\\Users\\sunny\\langgraph-end-to-end\\venv\\lib\\site-packages\\langchain_core\\language_models\\chat_models.py:843\u001b[0m, in \u001b[0;36mBaseChatModel.generate_prompt\u001b[1;34m(self, prompts, stop, callbacks, **kwargs)\u001b[0m\n\u001b[0;32m    835\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mgenerate_prompt\u001b[39m(\n\u001b[0;32m    836\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    837\u001b[0m     prompts: \u001b[38;5;28mlist\u001b[39m[PromptValue],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    840\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[0;32m    841\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m LLMResult:\n\u001b[0;32m    842\u001b[0m     prompt_messages \u001b[38;5;241m=\u001b[39m [p\u001b[38;5;241m.\u001b[39mto_messages() \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m prompts]\n\u001b[1;32m--> 843\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgenerate(prompt_messages, stop\u001b[38;5;241m=\u001b[39mstop, callbacks\u001b[38;5;241m=\u001b[39mcallbacks, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\sunny\\langgraph-end-to-end\\venv\\lib\\site-packages\\langchain_core\\language_models\\chat_models.py:683\u001b[0m, in \u001b[0;36mBaseChatModel.generate\u001b[1;34m(self, messages, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001b[0m\n\u001b[0;32m    680\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(messages):\n\u001b[0;32m    681\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    682\u001b[0m         results\u001b[38;5;241m.\u001b[39mappend(\n\u001b[1;32m--> 683\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate_with_cache(\n\u001b[0;32m    684\u001b[0m                 m,\n\u001b[0;32m    685\u001b[0m                 stop\u001b[38;5;241m=\u001b[39mstop,\n\u001b[0;32m    686\u001b[0m                 run_manager\u001b[38;5;241m=\u001b[39mrun_managers[i] \u001b[38;5;28;01mif\u001b[39;00m run_managers \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    687\u001b[0m                 \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m    688\u001b[0m             )\n\u001b[0;32m    689\u001b[0m         )\n\u001b[0;32m    690\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    691\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m run_managers:\n",
      "File \u001b[1;32mc:\\Users\\sunny\\langgraph-end-to-end\\venv\\lib\\site-packages\\langchain_core\\language_models\\chat_models.py:908\u001b[0m, in \u001b[0;36mBaseChatModel._generate_with_cache\u001b[1;34m(self, messages, stop, run_manager, **kwargs)\u001b[0m\n\u001b[0;32m    906\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    907\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m inspect\u001b[38;5;241m.\u001b[39msignature(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate)\u001b[38;5;241m.\u001b[39mparameters\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_manager\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m--> 908\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate(\n\u001b[0;32m    909\u001b[0m             messages, stop\u001b[38;5;241m=\u001b[39mstop, run_manager\u001b[38;5;241m=\u001b[39mrun_manager, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[0;32m    910\u001b[0m         )\n\u001b[0;32m    911\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    912\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate(messages, stop\u001b[38;5;241m=\u001b[39mstop, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\sunny\\langgraph-end-to-end\\venv\\lib\\site-packages\\langchain_groq\\chat_models.py:480\u001b[0m, in \u001b[0;36mChatGroq._generate\u001b[1;34m(self, messages, stop, run_manager, **kwargs)\u001b[0m\n\u001b[0;32m    475\u001b[0m message_dicts, params \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_create_message_dicts(messages, stop)\n\u001b[0;32m    476\u001b[0m params \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m    477\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams,\n\u001b[0;32m    478\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m    479\u001b[0m }\n\u001b[1;32m--> 480\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclient\u001b[38;5;241m.\u001b[39mcreate(messages\u001b[38;5;241m=\u001b[39mmessage_dicts, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams)\n\u001b[0;32m    481\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_create_chat_result(response)\n",
      "File \u001b[1;32mc:\\Users\\sunny\\langgraph-end-to-end\\venv\\lib\\site-packages\\groq\\resources\\chat\\completions.py:322\u001b[0m, in \u001b[0;36mCompletions.create\u001b[1;34m(self, messages, model, frequency_penalty, function_call, functions, logit_bias, logprobs, max_completion_tokens, max_tokens, n, parallel_tool_calls, presence_penalty, reasoning_format, response_format, seed, service_tier, stop, stream, temperature, tool_choice, tools, top_logprobs, top_p, user, extra_headers, extra_query, extra_body, timeout)\u001b[0m\n\u001b[0;32m    166\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mcreate\u001b[39m(\n\u001b[0;32m    167\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    168\u001b[0m     \u001b[38;5;241m*\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    198\u001b[0m     timeout: \u001b[38;5;28mfloat\u001b[39m \u001b[38;5;241m|\u001b[39m httpx\u001b[38;5;241m.\u001b[39mTimeout \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m|\u001b[39m NotGiven \u001b[38;5;241m=\u001b[39m NOT_GIVEN,\n\u001b[0;32m    199\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ChatCompletion \u001b[38;5;241m|\u001b[39m Stream[ChatCompletionChunk]:\n\u001b[0;32m    200\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    201\u001b[0m \u001b[38;5;124;03m    Creates a model response for the given chat conversation.\u001b[39;00m\n\u001b[0;32m    202\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    320\u001b[0m \u001b[38;5;124;03m      timeout: Override the client-level default timeout for this request, in seconds\u001b[39;00m\n\u001b[0;32m    321\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 322\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_post\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    323\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/openai/v1/chat/completions\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    324\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaybe_transform\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    325\u001b[0m \u001b[43m            \u001b[49m\u001b[43m{\u001b[49m\n\u001b[0;32m    326\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmessages\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    327\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmodel\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    328\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfrequency_penalty\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfrequency_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    329\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfunction_call\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunction_call\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    330\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfunctions\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunctions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    331\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlogit_bias\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogit_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    332\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlogprobs\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    333\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmax_completion_tokens\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_completion_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    334\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmax_tokens\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    335\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mn\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    336\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mparallel_tool_calls\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mparallel_tool_calls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    337\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpresence_penalty\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpresence_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    338\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mreasoning_format\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mreasoning_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    339\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mresponse_format\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    340\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mseed\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    341\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mservice_tier\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mservice_tier\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    342\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstop\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    343\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstream\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    344\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtemperature\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    345\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtool_choice\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtool_choice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    346\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtools\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtools\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    347\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtop_logprobs\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_logprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    348\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtop_p\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_p\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    349\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43muser\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43muser\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    350\u001b[0m \u001b[43m            \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    351\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcompletion_create_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCompletionCreateParams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    352\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    353\u001b[0m \u001b[43m        \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmake_request_options\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    354\u001b[0m \u001b[43m            \u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_headers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_query\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_query\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_body\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_body\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\n\u001b[0;32m    355\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    356\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mChatCompletion\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    357\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    358\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mStream\u001b[49m\u001b[43m[\u001b[49m\u001b[43mChatCompletionChunk\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    359\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\sunny\\langgraph-end-to-end\\venv\\lib\\site-packages\\groq\\_base_client.py:1266\u001b[0m, in \u001b[0;36mSyncAPIClient.post\u001b[1;34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[0m\n\u001b[0;32m   1252\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mpost\u001b[39m(\n\u001b[0;32m   1253\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   1254\u001b[0m     path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1261\u001b[0m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   1262\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ResponseT \u001b[38;5;241m|\u001b[39m _StreamT:\n\u001b[0;32m   1263\u001b[0m     opts \u001b[38;5;241m=\u001b[39m FinalRequestOptions\u001b[38;5;241m.\u001b[39mconstruct(\n\u001b[0;32m   1264\u001b[0m         method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpost\u001b[39m\u001b[38;5;124m\"\u001b[39m, url\u001b[38;5;241m=\u001b[39mpath, json_data\u001b[38;5;241m=\u001b[39mbody, files\u001b[38;5;241m=\u001b[39mto_httpx_files(files), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions\n\u001b[0;32m   1265\u001b[0m     )\n\u001b[1;32m-> 1266\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(ResponseT, \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[1;32mc:\\Users\\sunny\\langgraph-end-to-end\\venv\\lib\\site-packages\\groq\\_base_client.py:958\u001b[0m, in \u001b[0;36mSyncAPIClient.request\u001b[1;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[0;32m    955\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    956\u001b[0m     retries_taken \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m--> 958\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    959\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    960\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    961\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    962\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    963\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretries_taken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretries_taken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    964\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\sunny\\langgraph-end-to-end\\venv\\lib\\site-packages\\groq\\_base_client.py:1061\u001b[0m, in \u001b[0;36mSyncAPIClient._request\u001b[1;34m(self, cast_to, options, retries_taken, stream, stream_cls)\u001b[0m\n\u001b[0;32m   1058\u001b[0m         err\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mread()\n\u001b[0;32m   1060\u001b[0m     log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRe-raising status error\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m-> 1061\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_status_error_from_response(err\u001b[38;5;241m.\u001b[39mresponse) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1063\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_response(\n\u001b[0;32m   1064\u001b[0m     cast_to\u001b[38;5;241m=\u001b[39mcast_to,\n\u001b[0;32m   1065\u001b[0m     options\u001b[38;5;241m=\u001b[39moptions,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1069\u001b[0m     retries_taken\u001b[38;5;241m=\u001b[39mretries_taken,\n\u001b[0;32m   1070\u001b[0m )\n",
      "\u001b[1;31mBadRequestError\u001b[0m: Error code: 400 - {'error': {'message': \"Failed to call a function. Please adjust your prompt. See 'failed_generation' for more details.\", 'type': 'invalid_request_error', 'code': 'tool_use_failed', 'failed_generation': ''}}"
     ]
    }
   ],
   "source": [
    "# With the graph created, we can now invoke it and see how it performs!\n",
    "for s in app.stream({\"messages\": [(\"user\", \"What's the square root of 42?\")]}, subgraphs=True):\n",
    "    print(s)\n",
    "    print(\"----\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "below my goto**********************************\n",
      "researcher\n",
      "below my goto**********************************\n",
      "researcher\n",
      "below my goto**********************************\n",
      "researcher\n",
      "below my goto**********************************\n",
      "researcher\n",
      "below my goto**********************************\n",
      "researcher\n",
      "below my goto**********************************\n",
      "FINISH\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((),\n",
       " {'messages': [HumanMessage(content=\"What's the square root of 42?\", additional_kwargs={}, response_metadata={}, id='094973c8-591b-499c-8a3d-e8f5d94b3984'),\n",
       "   HumanMessage(content='The square root of 42 is approximately 6.4807.', additional_kwargs={}, response_metadata={}, name='researcher', id='22cfec39-cf47-4d96-b834-fd9d78389866'),\n",
       "   HumanMessage(content='The square root of 42 is approximately 6.4807. This is an irrational number, meaning it cannot be expressed exactly as a simple fraction and its decimal representation is non-repeating and infinite.', additional_kwargs={}, response_metadata={}, name='researcher', id='9e1e6f5b-d324-42e7-a61f-b4e121808bc0'),\n",
       "   HumanMessage(content=\"\\n\\nOkay, so I need to figure out the square root of 42. Hmm, I remember that the square root of a number is a value that, when multiplied by itself, gives the original number. So, I'm looking for a number that, when I square it, equals 42.\\n\\nFirst, I'll think about perfect squares near 42 to get an estimate. I know that 6 squared is 36 and 7 squared is 49. So, the square root of 42 must be somewhere between 6 and 7. \\n\\nTo get a better approximation, I can try numbers between 6 and 7. Let's start with 6.5. If I square 6.5, I get 42.25. That's a bit higher than 42, so maybe 6.48. \\n\\nCalculating 6.48 squared: 6 * 6 is 36, 0.48 * 6 is 2.88, and 0.48 squared is 0.2304. Adding those up: 36 + 2.88 + 2.88 + 0.2304 = 41.98, which is very close to 42. So, 6.48 is a good approximation.\\n\\nTherefore, the square root of 42 is approximately 6.4807. This makes sense because 6.4807 squared is roughly 42, confirming the calculation.\", additional_kwargs={}, response_metadata={}, name='researcher', id='0cbb8596-44f6-448b-80e5-836ae8c0c013'),\n",
       "   HumanMessage(content='\\n\\nThe square root of 42 is approximately 6.4807.', additional_kwargs={}, response_metadata={}, name='researcher', id='b7892966-9e7e-4c06-8e6b-38e5f3d6333d'),\n",
       "   HumanMessage(content='', additional_kwargs={}, response_metadata={}, name='researcher', id='9485d49a-237a-46ac-a543-09ab9620821e')],\n",
       "  'next': '__end__'})"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "app.invoke({\"messages\": [(\"user\", \"What's the square root of 42?\")]}, subgraphs=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "below my goto**********************************\n",
      "coder\n",
      "below my goto**********************************\n",
      "coder\n",
      "below my goto**********************************\n",
      "FINISH\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((),\n",
       " {'messages': [HumanMessage(content='What is an efficient Python code to get prime numbers?', additional_kwargs={}, response_metadata={}, id='3ea6d4d1-bf79-4962-aeb7-b4ab9d61236b'),\n",
       "   HumanMessage(content='To efficiently find prime numbers using Python, the Sieve of Eratosthenes algorithm is a highly effective method. Here\\'s an implementation of the Sieve of Eratosthenes:\\n\\n<tool_call>{\"name\": \"python_repl_tool\", \"arguments\": {\"code\": \"def sieve_of_eratosthenes(n):\\\\n    if n < 2:\\\\n        return []\\\\n    prime = [True] * (n + 1)\\\\n    prime[0], prime[1] = False, False\\\\n    for i in range(2, int(n ** 0.5) + 1):\\\\n        if prime[i]:\\\\n            for j in range(i*i, n+1, i):\\\\n                prime[j] = False\\\\n    primes = [i for i, is_prime in enumerate(prime) if is_prime]\\\\n    return primes\\\\n\\\\nprint(sieve_of_eratosthenes(20))\"}}', additional_kwargs={}, response_metadata={}, name='coder', id='301bd894-8096-4ab7-87b8-e4796f363704'),\n",
       "   HumanMessage(content=\"The Sieve of Eratosthenes is an efficient algorithm for finding all primes up to a given limit. Here's how you can implement it in Python:\\n\\n```python\\ndef sieve_of_eratosthenes(n):\\n    if n < 2:\\n        return []\\n    prime = [True] * (n + 1)\\n    prime[0], prime[1] = False, False\\n    for i in range(2, int(n ** 0.5) + 1):\\n        if prime[i]:\\n            for j in range(i*i, n+1, i):\\n                prime[j] = False\\n    primes = [i for i, is_prime in enumerate(prime) if is_prime]\\n    return primes\\n\\nprint(sieve_of_eratosthenes(20))\\n```\\n\\nThis code will output: `[2, 3, 5, 7, 11, 13, 17, 19]`, which are the prime numbers up to 20.\", additional_kwargs={}, response_metadata={}, name='coder', id='34e8e986-4085-4221-98d6-c5268e9c2b12')],\n",
       "  'next': '__end__'})"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "app.invoke({\"messages\": [(\"user\", \"What is an efficient Python code to get prime numbers?\")]}, subgraphs=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
